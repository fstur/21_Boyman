{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67dfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de010f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ome_types\n",
    "from ome_types.model import StructuredAnnotations, XMLAnnotation\n",
    "import pandas as pd\n",
    "from ptufile import PtuFile\n",
    "from scipy import interpolate\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f7e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory, where the raw .ptu files are stored\n",
    "ptu_dir = Path(\n",
    "    r'Z:\\zmbstaff\\9309\\Raw_Data\\240531_Inhibitor_screening_1\\ptu_exports2\\data.sptw'\n",
    ")\n",
    "# directory, where the mask-TIFFs are stored\n",
    "mask_dir = Path(\n",
    "    r'Z:\\zmbstaff\\9309\\Raw_Data\\240531_Inhibitor_screening_1\\converted_data\\roiImages'\n",
    ")\n",
    "# directory, where the preprocessed roiExtracts will be stored\n",
    "export_dir_ptus = Path(\n",
    "    r'Z:\\zmbstaff\\9309\\Raw_Data\\240531_Inhibitor_screening_1\\converted_data\\roiExtract'\n",
    ")\n",
    "# path to the exported IRF xlsx file\n",
    "fn_IRF_xlsx = Path(\n",
    "    r'Z:\\zmbstaff\\9309\\Raw_Data\\240531_Inhibitor_screening_1\\IRF\\export_IRF_data.xlsx'\n",
    ")\n",
    "# directory, where the IRF data will be stored\n",
    "export_dir_IRF = Path(\n",
    "    r'Z:\\zmbstaff\\9309\\Raw_Data\\240531_Inhibitor_screening_1\\converted_data\\IRF'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db918f7",
   "metadata": {},
   "source": [
    "## Load ptu files, extract ROIs and save as ome.tiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03fc64-197e-4702-9dcc-8f575462ac67",
   "metadata": {},
   "source": [
    "### Load metadata from ptu files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aef4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ptu files\n",
    "fns_ptu = list(ptu_dir.glob(\"*.ptu\"))\n",
    "# find mask files\n",
    "fns_mask = list(mask_dir.glob(\"*.tif\"))\n",
    "names_mask = [fn_mask.stem.split('_mask')[0] for fn_mask in fns_mask]\n",
    "\n",
    "# find ptu files that have a matching mask file (ignore others)\n",
    "matching_fns = []\n",
    "for name_mask in names_mask:\n",
    "    matching_fns_ptu = [fn_ptu for fn_ptu in fns_ptu if name_mask == fn_ptu.stem]\n",
    "    if len(matching_fns_ptu) == 1:\n",
    "        matching_fns.append(matching_fns_ptu[0])\n",
    "    elif len(matching_fns_ptu) > 1:\n",
    "        raise ValueError(f\"Multiple matching names found for mask file: {name_mask}\")\n",
    "    else:\n",
    "        raise ValueError(f\"No matching name found for mask file: {name_mask}\")\n",
    "\n",
    "fns_ptu = matching_fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7dec7d",
   "metadata": {},
   "source": [
    "### Load metadata from ptu files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a86417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load metadata from ptu files\n",
    "\n",
    "@dask.delayed\n",
    "def lazy_load_ptu_metadata(fn):\n",
    "    ptu = PtuFile(fn)\n",
    "    assert ptu.dims == ('T', 'Y', 'X', 'C', 'H')\n",
    "\n",
    "    # DETERMINE DATA WITHIN PULSE\n",
    "    time = ptu.coords['H']\n",
    "    # determine timepoints within pulse (1/repetition rate)\n",
    "    last = np.where(time <= 1/ptu.frequency)[0][-1]\n",
    "    # NOTE: logically one would take last+1 at this point, but somehow the data\n",
    "    # looks more continuous this way. The last timepoint within the pulse\n",
    "    # somehow has fewer photons, so we leave it out.\n",
    "    t_start = time[0]\n",
    "    t_end = time[last-1]\n",
    "    t_step = (t_end-t_start)/(last-1)\n",
    "\n",
    "    return (t_start, t_end, t_step), ptu.frequency, time[:last].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e279b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dask.compute(*[lazy_load_ptu_metadata(fn) for fn in fns_ptu])\n",
    "\n",
    "# check if metadata for all files is the same\n",
    "assert all(e[:2]==output[0][:2] for e in output)\n",
    "\n",
    "(t_start, t_end, t_step), frequency, micro_times = output[0]\n",
    "f\"repetition rate is {frequency/10**6:.3f} MHz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d074a1",
   "metadata": {},
   "source": [
    "### Load ptu files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c1f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load ptu files\n",
    "\n",
    "@dask.delayed\n",
    "def lazy_load_ptu(fn):\n",
    "    ptu = PtuFile(fn)\n",
    "    assert ptu.dims == ('T', 'Y', 'X', 'C', 'H')\n",
    "\n",
    "    # DETERMINE DATA WITHIN PULSE\n",
    "    time = ptu.coords['H']\n",
    "    # determine timepoints within pulse (1/repetition rate)\n",
    "    last = np.where(time <= 1/ptu.frequency)[0][-1]\n",
    "    # NOTE: logically one would take last+1 at this point, but somehow the data\n",
    "    # looks more continuous this way. The last timepoint within the pulse\n",
    "    # somehow has fewer photons, so we leave it out.\n",
    "\n",
    "    # LOAD DECAY-IMAGES\n",
    "    # sum all repetitions\n",
    "    flim_img = ptu[...,:last].sum(axis=0).astype('uint16')\n",
    "    \n",
    "    # get flim-img into correct shape (make sure it matches mask!)\n",
    "    data = np.transpose(flim_img, (3,2,1,0))\n",
    "    data = np.flip(data, axis=3)\n",
    "    \n",
    "    return data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2995a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = lazy_load_ptu(fns_ptu[0]).compute()\n",
    "\n",
    "arrays = [\n",
    "    da.from_delayed(\n",
    "        lazy_load_ptu(fn),\n",
    "        dtype=meta.dtype,\n",
    "        shape=meta.shape\n",
    "    )\n",
    "    for fn in fns_ptu]\n",
    "\n",
    "flim_imgs_da = da.stack(arrays, axis=0)\n",
    "flim_imgs_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a781a95",
   "metadata": {},
   "source": [
    "### Load masks files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "368e0955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load masks\n",
    "\n",
    "@dask.delayed\n",
    "def lazy_load_mask(fn):\n",
    "    mask = tifffile.imread(fn)    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = lazy_load_mask(fns_mask[0]).compute()\n",
    "\n",
    "arrays = [\n",
    "    da.from_delayed(\n",
    "        lazy_load_mask(fn),\n",
    "        dtype=meta.dtype,\n",
    "        shape=meta.shape\n",
    "    )\n",
    "    for fn in fns_mask]\n",
    "\n",
    "masks_da = da.stack(arrays, axis=0)\n",
    "masks_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].imshow(masks_da[0])\n",
    "axs[1].imshow(flim_imgs_da[0].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca446b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = masks_da.max().compute()\n",
    "max_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7949f",
   "metadata": {},
   "source": [
    "### Extract ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f854f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def lazy_extract_roi(flim_img, mask, max_label):\n",
    "    decays = np.zeros((flim_img.shape[0], max_label), dtype=flim_img.dtype)\n",
    "    for t in range(len(decays)):\n",
    "        for i in range(max_label):\n",
    "            decays[t, i] = flim_img[t][mask == i+1].sum()\n",
    "    return np.reshape(decays, decays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17003b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = lazy_extract_roi(flim_imgs_da[0], masks_da[0], max_label).compute()\n",
    "\n",
    "arrays = [\n",
    "    da.from_delayed(\n",
    "        lazy_extract_roi(flim_img_da, mask_da, max_label),\n",
    "        dtype=meta.dtype,\n",
    "        shape=meta.shape\n",
    "    )\n",
    "    for flim_img_da, mask_da in zip(flim_imgs_da, masks_da)]\n",
    "\n",
    "roiExtracts_da = da.stack(arrays, axis=0)\n",
    "roiExtracts_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7769036",
   "metadata": {},
   "source": [
    "### Save as ome.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f937e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_omexml(data, flim_start, flim_end, flim_step):\n",
    "    assert len(data.shape) == 3\n",
    "    assert data.shape[-1] == 1\n",
    "\n",
    "    # create ome Image object\n",
    "    omexml = tifffile.OmeXml()\n",
    "    omexml.addimage(\n",
    "        dtype=data.dtype,\n",
    "        shape=data.shape,\n",
    "        storedshape=(data.shape[0], 1, 1, data.shape[1], 1, 1),\n",
    "        axes='TYX',\n",
    "    )\n",
    "    ome_image = ome_types.from_xml(omexml.tostring()).images[0]\n",
    "    ome_image.annotation_refs = [{'id': 'Annotation:0'}]\n",
    "\n",
    "    # construct XML Annotation for FLIM metadata\n",
    "    root = ET.Element('Modulo', {'namespace': 'http://www.openmicroscopy.org/Schemas/Additions/2011-09'})\n",
    "    modulo_along_t = ET.SubElement(\n",
    "        root,\n",
    "        'ModuloAlongT',\n",
    "        {\n",
    "            'End': str(flim_end * 10**9),\n",
    "            'Start': str(flim_start * 10**9),\n",
    "            'Step': str(flim_step * 10**9),\n",
    "            'Type': 'lifetime',\n",
    "            'TypeDescription': '',\n",
    "            'Unit': 'ns'\n",
    "        }\n",
    "    )\n",
    "    tree = ET.ElementTree(root)\n",
    "    xml_str_modulo = ET.tostring(root, encoding='unicode')\n",
    "    sa = StructuredAnnotations(\n",
    "        xml_annotations=[\n",
    "            XMLAnnotation(\n",
    "                id='Annotation:0',\n",
    "                namespace='openmicroscopy.org/omero/dimension/modulo',\n",
    "                value=xml_str_modulo,\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # combine everything into an OME object\n",
    "    ome = ome_types.OME(\n",
    "        images=[ome_image],\n",
    "        structured_annotations=sa,\n",
    "    )\n",
    "\n",
    "    return ome.to_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54e1b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def lazy_save_roiExtract(roiExtract, export_dir_ptus, name, time_metadata):\n",
    "    data = roiExtract.reshape(roiExtract.shape + (1,))\n",
    "    t_start, t_end, t_step = time_metadata\n",
    "    omexml = construct_omexml(data, t_start, t_end, t_step)\n",
    "\n",
    "    save_name = export_dir_ptus / f\"{name}.ome.tiff\"\n",
    "\n",
    "    with tifffile.TiffWriter(save_name, ome=False, shaped=False) as tif:\n",
    "        for frame in data:\n",
    "            tif.write(frame, description=omexml, contiguous=True)\n",
    "            omexml = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "034a7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make export directory:\n",
    "os.makedirs(export_dir_ptus, exist_ok=True)\n",
    "\n",
    "# run the saving\n",
    "names = [fn.stem for fn in fns_ptu]\n",
    "_ = dask.compute(\n",
    "    *[\n",
    "        lazy_save_roiExtract(\n",
    "            roiExtract_da,\n",
    "            export_dir_ptus,\n",
    "            name,\n",
    "            (t_start, t_end, t_step)\n",
    "        )\n",
    "        for roiExtract_da, name in zip(roiExtracts_da, names)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc767d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5608f778",
   "metadata": {},
   "source": [
    "## Combine exported IRFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dc7ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IRF DATA\n",
    "# read IRFs\n",
    "df = pd.read_excel(fn_IRF_xlsx, header=[0, 1])\n",
    "\n",
    "# extract IRF columns\n",
    "columns = df.columns.get_level_values(0).unique()\n",
    "columns = columns[columns.str.contains('IRF')]\n",
    "\n",
    "# extract IRF data\n",
    "irf_data = []\n",
    "for column in columns:\n",
    "    time = df[column].iloc[:, 0].dropna().to_numpy()\n",
    "    irf = df[column].iloc[:, 1].dropna().to_numpy()\n",
    "    irf_data.append(np.array([time, irf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot raw IRFs\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "for data in irf_data:\n",
    "    time, irf = data\n",
    "    irf_normalized = irf\n",
    "    ax1.plot(time, irf_normalized)\n",
    "    ax2.semilogy(time, irf_normalized)\n",
    "\n",
    "ax1.set_xlabel('Time (ns)')\n",
    "ax1.set_ylabel('IRF (a.u.)')\n",
    "ax1.set_title('Exported IRFs (linear)')\n",
    "\n",
    "ax2.set_xlabel('Time (ns)')\n",
    "ax2.set_ylabel('IRF (a.u.)')\n",
    "ax2.set_title('Exported IRFs (log)')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85bc380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE IRFs\n",
    "# interpolate IRFs to match FLIM data\n",
    "irf_data_interp = []\n",
    "IRF_time = micro_times * 10**9 # time from FLIM data in ns\n",
    "for data in irf_data:\n",
    "    interp = interpolate.CubicSpline(data[0], data[1], extrapolate=0)\n",
    "    data_interp = np.nan_to_num(interp(IRF_time), nan=0)\n",
    "    irf_data_interp.append(np.array([IRF_time, data_interp]))\n",
    "\n",
    "# normalize IRFs\n",
    "irf_data_norm = []\n",
    "irf_data_interp_norm = []\n",
    "for data, data_interp in zip(irf_data, irf_data_interp):\n",
    "    #norm = data_interp[1].max()  # normalize to max\n",
    "    norm = data_interp[1].sum()  # normalize to sum\n",
    "    irf_data_norm.append(np.array([data[0], data[1] / norm]))\n",
    "    irf_data_interp_norm.append(np.array([data_interp[0], data_interp[1] / norm]))\n",
    "\n",
    "# take mean of normalized IRFs\n",
    "irf_data_interp_norm_mean = np.mean(np.array(irf_data_interp_norm), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d60204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n",
    "xlims = (\n",
    "    min([min(data[0]) for data in irf_data]),\n",
    "    max([max(data[0]) for data in irf_data])\n",
    ")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "for data, data_interp in zip(irf_data_norm, irf_data_interp_norm):\n",
    "    ax1.plot(data[0], data[1], 'o')\n",
    "    ax1.plot(data_interp[0], data_interp[1])\n",
    "\n",
    "    ax2.semilogy(data[0], data[1], 'o')\n",
    "    ax2.plot(data_interp[0], data_interp[1])\n",
    "\n",
    "ax1.plot(irf_data_interp_norm_mean[0], irf_data_interp_norm_mean[1], 'k--', label='Mean')\n",
    "ax2.plot(irf_data_interp_norm_mean[0], irf_data_interp_norm_mean[1], 'k--')\n",
    "\n",
    "ax1.set_xlabel('Time (ns)')\n",
    "ax1.set_ylabel('IRF (a.u.)')\n",
    "ax1.set_title('Normalized IRFs & mean (linear)')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_xlabel('Time (ns)')\n",
    "ax2.set_ylabel('IRF (a.u.)')\n",
    "ax2.set_title('Normalized IRFs & mean (log)')\n",
    "\n",
    "ax1.set_xlim(xlims[0], xlims[1])\n",
    "ax2.set_xlim(xlims[0], xlims[1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf43414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make export directory:\n",
    "os.makedirs(export_dir_IRF, exist_ok=True)\n",
    "\n",
    "# export IRF as csv\n",
    "export_time = (irf_data_interp_norm_mean[0] * 10**3).astype('int')\n",
    "export_data = irf_data_interp_norm_mean[1] / irf_data_interp_norm_mean[1].max()\n",
    "irf_df = pd.DataFrame({'t': export_time, 'irf_ch1': export_data})\n",
    "irf_df.to_csv(export_dir_IRF / 'irf_est.csv', index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f19d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zmb_21] *",
   "language": "python",
   "name": "conda-env-zmb_21-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
